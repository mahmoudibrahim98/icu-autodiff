{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import torch \n",
                "import sys\n",
                "import os\n",
                "parent_dir = os.path.dirname(os.path.abspath(''))\n",
                "sys.path.append(parent_dir)\n",
                "\n",
                "import data_access.base_loader as base_loader\n",
                "import data_access.ricu_loader as ricu_loader\n",
                "import os\n",
                "import datetime\n",
                "import wandb\n",
                "import ast\n",
                "import logging\n",
                "import json\n",
                "\n",
                "import timeautodiff.processing_simple as processing\n",
                "import timeautodiff.helper_simple as tdf_helper\n",
                "import timeautodiff.timeautodiff_v4_efficient_simple as timeautodiff\n",
                "import evaluation_framework.vis as vis\n",
                "import tqdm.notebook\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/mnthpc/netapp01/projects/AI4Health/notebooks/ibrahimm/Generative-Models/ehr/3_timeautodiff-mvp/data_access/base_loader.py:596: UserWarning: This will split the data into train, val, test sets stratified on outcome and demographics_to_stratify_on, according to the train_fraction and val_fraction\n",
                        "  warnings.warn(\"This will split the data into train, val, test sets stratified on outcome and demographics_to_stratify_on, according to the train_fraction and val_fraction\")\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "dict_keys(['X_original_train', 'X_original_val', 'X_original_test', 'X_imputed_train', 'X_imputed_val', 'X_imputed_test', 'm_train', 'm_val', 'm_test', 'delta_t_train', 'delta_t_val', 'delta_t_test', 'feature_names'])"
                        ]
                    },
                    "execution_count": 5,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# splitting parameters\n",
                "train_fraction = 0.45\n",
                "val_fraction = 0.1\n",
                "oracle_fraction = 0\n",
                "oracle_min = 100\n",
                "intersectional_min_threshold = 100\n",
                "intersectional_max_threshold = 1000\n",
                "\n",
                "\n",
                "# # data parameters\n",
                "data_name = 'mimic' # 'mimic' 'eicu'\n",
                "task_name = 'mortality24' # 'aki' 'kidney_function' 'los' 'los_24' 'mortality24' \n",
                "static_var = 'ethnicity'\n",
                "features = None\n",
                "ricu_dataset_path = f'../raw_data/{task_name}/{data_name}'\n",
                "processed_output_path = f'outputs/{task_name}/{data_name}/processed/'\n",
                "intermed_output_path = f'outputs/{task_name}/{data_name}/intermed/'\n",
                "seed = 0\n",
                "\n",
                "simple_imputation = True\n",
                "mode = 'processed'\n",
                "processed_data_timestamp = '20250527114407'  # change this to the timestamp of the processed data\n",
                "intermed_data_timestamp = None\n",
                "\n",
                "standardize = False\n",
                "save_intermed_data = True\n",
                "save_processed_data = True\n",
                "split = True\n",
                "stratify =  False\n",
                "intersectional = False\n",
                "\n",
                "if split == False:\n",
                "    split_text = 'No Split'\n",
                "else:\n",
                "    split_text = 'Split'\n",
                "data_params = {\n",
                "    'processed_data_timestamp':processed_data_timestamp,\n",
                "    'task_name': task_name,\n",
                "    'data_name': data_name,\n",
                "    'train_fraction': train_fraction,\n",
                "    'val_fraction': val_fraction,\n",
                "    'test_fraction': 1 - train_fraction - val_fraction,\n",
                "    'oracle_fraction': oracle_fraction,\n",
                "    'oracle_min': oracle_min,\n",
                "    'intersectional_min_threshold': intersectional_min_threshold,\n",
                "    'intersectional_max_threshold': intersectional_max_threshold,\n",
                "    'split': split_text,\n",
                "    'standardize' : standardize,\n",
                "}\n",
                "\n",
                "loader = ricu_loader.RicuLoader(seed, task_name, data_name,static_var,ricu_dataset_path,simple_imputation,\n",
                "                                    features, processed_output_path,intermed_output_path)\n",
                "\n",
                "\n",
                "\n",
                "\n",
                "\n",
                "X_dict_tf, y_dict, static = loader.get_data(\n",
                "    mode='processed', \n",
                "    train_fraction=train_fraction,\n",
                "    val_fraction=val_fraction,\n",
                "    oracle_fraction=oracle_fraction,\n",
                "    oracle_min=oracle_min,\n",
                "    intersectional_min_threshold=intersectional_min_threshold,\n",
                "    intersectional_max_threshold=intersectional_max_threshold,\n",
                "    stratify=stratify,\n",
                "    intersectional=intersectional,\n",
                "    save_intermed_data=False,\n",
                "    save_processed_data=False,\n",
                "    demographics_to_stratify_on = ['age_group','ethnicity','gender'],\n",
                "    processed_timestamp=processed_data_timestamp\n",
                ")\n",
                "    \n",
                "if not isinstance(X_dict_tf, dict):\n",
                "    X_dict_tf = {file: X_dict_tf[file] for file in X_dict_tf.files}\n",
                "    y_dict = {file: y_dict[file] for file in y_dict.files}\n",
                "\n",
                "X_dict_tf.keys()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Shape of X train: (17157, 48, 25)\n",
                        "Shape of X Holdout: (17157, 48, 25)\n",
                        "Shape of X Holdout val: (3812, 48, 25)\n",
                        "Shape of y train: (17157,)\n",
                        "Shape of y Holdout: (17157,)\n",
                        "Shape of y Holdout val: (3812,)\n",
                        "Shape of c train: (17157, 3)\n",
                        "Shape of c Holdout: (17157, 3)\n",
                        "Shape of c Holdout val: (3812, 3)\n"
                    ]
                }
            ],
            "source": [
                "\n",
                "# most_important_features = [19, 27, 17, 35, 22, 44, 42, 43, 37, 26]\n",
                "X_train = X_dict_tf['X_imputed_train'][:,:,:]\n",
                "X_holdout = X_dict_tf['X_imputed_test'][:,:,:]\n",
                "X_holdout_val = X_dict_tf['X_imputed_val'][:,:,:]\n",
                "\n",
                "m_train = X_dict_tf['m_train'][:,:,:]\n",
                "m_holdout = X_dict_tf['m_test'][:,:,:]\n",
                "m_holdout_val = X_dict_tf['m_val'][:,:,:]\n",
                "\n",
                "feature_names = X_dict_tf['feature_names'][:]\n",
                "y_train = y_dict['y_train'][:]\n",
                "y_holdout = y_dict['y_test'][:]\n",
                "y_holdout_val = y_dict['y_val'][:]\n",
                "\n",
                "\n",
                "static_feature_to_include = ['ethnicity','gender','age_group']\n",
                "static_features_to_include_indices = sorted([y_dict['feature_names'].tolist().index(include)  for include in static_feature_to_include])\n",
                "c_train = y_dict['c_train'][:,static_features_to_include_indices]\n",
                "c_holdout = y_dict['c_test'][:,static_features_to_include_indices]\n",
                "c_holdout_val = y_dict['c_val'][:,static_features_to_include_indices]\n",
                "\n",
                "cond_names = y_dict['feature_names'][static_features_to_include_indices]\n",
                "\n",
                "\n",
                "\n",
                "top10_important_features = [19, 27, 17, 35, 22, 44, 42, 43, 37, 26]\n",
                "top3_important_features = [44,42,43]\n",
                "top6_important_features = [42, 22, 27, 35, 43, 17]\n",
                "\n",
                "important_features_names = X_dict_tf['feature_names'][top10_important_features]\n",
                "important_features_names\n",
                "\n",
                "X_train_10 = processing.normalize_and_reshape(X_train)\n",
                "X_train_10 = X_train_10[:,:,top10_important_features]\n",
                "\n",
                "print('Shape of X train:', X_train.shape)\n",
                "print('Shape of X Holdout:', X_holdout.shape)\n",
                "print('Shape of X Holdout val:', X_holdout_val.shape)\n",
                "\n",
                "print('Shape of y train:', y_train.shape)\n",
                "print('Shape of y Holdout:', y_holdout.shape)\n",
                "print('Shape of y Holdout val:', y_holdout_val.shape)\n",
                "\n",
                "print('Shape of c train:', c_train.shape)\n",
                "print('Shape of c Holdout:', c_holdout.shape)\n",
                "print('Shape of c Holdout val:', c_holdout_val.shape)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Model Loading"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "############ Evaluating timestamp 20250527_122626_10features_v4_efficient_simple_mimic_mortality24: ############\n",
                        "Latent features loaded successfully.\n",
                        "Latent features shape: torch.Size([17157, 25, 10])\n"
                    ]
                }
            ],
            "source": [
                "################################################################################################################\n",
                "# Model Evaluation\n",
                "################################################################################################################\n",
                "output_dir = f'outputs/{task_name}/{data_name}/TimeAutoDiff/'\n",
                "latest_diffusion_timestamp = sorted(os.listdir(output_dir))[-1]\n",
                "\n",
                "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
                "print(f\"############ Evaluating timestamp {latest_diffusion_timestamp}: ############\")\n",
                "\n",
                "model = tdf_helper.load_models_only(latest_diffusion_timestamp, task_name, data_name)\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [],
            "source": [
                "response_train, outcome_train, static_train, time_info_train = processing.process_data_for_synthesizer(X_train, y_train, c_train, top10_important_features)\n",
                "cond_train = torch.concatenate((static_train, outcome_train), axis=2)\n",
                "response_train = response_train.float()\n",
                "time_info_train = time_info_train.float()\n",
                "cond_train = cond_train.float()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Sampling"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "c0f500b83082435f81c39de9ce84ba44",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Generating Synthetic Data:   0%|          | 0/2 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "ename": "OutOfMemoryError",
                    "evalue": "CUDA out of memory. Tried to allocate 124.00 MiB. GPU 0 has a total capacity of 39.38 GiB of which 22.00 MiB is free. Process 3372021 has 678.00 MiB memory in use. Process 3726096 has 4.51 GiB memory in use. Process 4160385 has 22.46 GiB memory in use. Process 447704 has 798.00 MiB memory in use. Process 1480267 has 8.30 GiB memory in use. Process 1693100 has 928.00 MiB memory in use. Including non-PyTorch memory, this process has 1.71 GiB memory in use. Of the allocated memory 1.04 GiB is allocated by PyTorch, and 177.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
                        "\u001b[31mOutOfMemoryError\u001b[39m                          Traceback (most recent call last)",
                        "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      6\u001b[39m n_generations = \u001b[32m2\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm.notebook.tqdm(\u001b[38;5;28mrange\u001b[39m(n_generations), desc=\u001b[33m\"\u001b[39m\u001b[33mGenerating Synthetic Data\u001b[39m\u001b[33m\"\u001b[39m, leave=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m     _synth_data = \u001b[43mtdf_helper\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_synthetic_data_in_batches\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcond_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_info_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m                                                                       \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m10000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m     _synth_data_y = cond_train[:, \u001b[32m0\u001b[39m, -\u001b[32m1\u001b[39m]\n\u001b[32m     14\u001b[39m     synth_data_list.append(_synth_data.cpu().numpy())\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m/mnthpc/netapp01/projects/AI4Health/notebooks/ibrahimm/Generative-Models/ehr/3_timeautodiff-mvp/timeautodiff/helper_simple.py:268\u001b[39m, in \u001b[36mgenerate_synthetic_data_in_batches\u001b[39m\u001b[34m(models, cond, time_info, batch_size)\u001b[39m\n\u001b[32m    264\u001b[39m cond_batch = cond[start:end]\n\u001b[32m    265\u001b[39m time_info_batch = time_info[start:end]\n\u001b[32m--> \u001b[39m\u001b[32m268\u001b[39m _synth_data = \u001b[43mgenerate_synthetic_data_simple\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcond_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_info_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    271\u001b[39m \u001b[38;5;66;03m# Append the results to the lists\u001b[39;00m\n\u001b[32m    272\u001b[39m synth_data_batches.append(_synth_data)\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m/mnthpc/netapp01/projects/AI4Health/notebooks/ibrahimm/Generative-Models/ehr/3_timeautodiff-mvp/timeautodiff/helper_simple.py:232\u001b[39m, in \u001b[36mgenerate_synthetic_data_simple\u001b[39m\u001b[34m(models, cond, time_info, numerical_processing, unprocess)\u001b[39m\n\u001b[32m    229\u001b[39m t_grid = torch.linspace(\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, Seq_len).view(\u001b[32m1\u001b[39m, -\u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m).to(device).repeat(Batch_size, \u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m)\n\u001b[32m    231\u001b[39m \u001b[38;5;66;03m# Generate samples\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m232\u001b[39m samples = \u001b[43mtimeautodiff\u001b[49m\u001b[43m.\u001b[49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt_grid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSeq_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlat_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiff\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcond\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_info\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    234\u001b[39m \u001b[38;5;66;03m# Apply decoder to generated latent vector\u001b[39;00m\n\u001b[32m    235\u001b[39m gen_output = ae.decoder(samples)\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/projects/AI4Health/notebooks/ibrahimm/Generative-Models/ehr/3_timeautodiff-mvp/.venv/lib/python3.11/site-packages/torch/utils/_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m/mnthpc/netapp01/projects/AI4Health/notebooks/ibrahimm/Generative-Models/ehr/3_timeautodiff-mvp/timeautodiff/timeautodiff_v4_efficient_simple.py:1020\u001b[39m, in \u001b[36msample\u001b[39m\u001b[34m(t, B, T, F, model, cond, time_info)\u001b[39m\n\u001b[32m   1016\u001b[39m     z = torch.randn(B, T, F).to(device)\n\u001b[32m   1018\u001b[39m     i = torch.Tensor([diff_step]).expand_as(x[...,:\u001b[32m1\u001b[39m]).to(device)\n\u001b[32m-> \u001b[39m\u001b[32m1020\u001b[39m     cond_noise = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcond\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_info\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1022\u001b[39m     x = (\u001b[32m1\u001b[39m/(\u001b[32m1\u001b[39m - beta).sqrt()) * (x - beta * cond_noise / (\u001b[32m1\u001b[39m - alpha).sqrt()) + beta.sqrt() * z\n\u001b[32m   1023\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/projects/AI4Health/notebooks/ibrahimm/Generative-Models/ehr/3_timeautodiff-mvp/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/projects/AI4Health/notebooks/ibrahimm/Generative-Models/ehr/3_timeautodiff-mvp/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m/mnthpc/netapp01/projects/AI4Health/notebooks/ibrahimm/Generative-Models/ehr/3_timeautodiff-mvp/timeautodiff/timeautodiff_v4_efficient_simple.py:858\u001b[39m, in \u001b[36mBiRNN_score.forward\u001b[39m\u001b[34m(self, x, t, i, cond, time_info)\u001b[39m\n\u001b[32m    855\u001b[39m time_info = \u001b[38;5;28mself\u001b[39m.time_encode(time_info)\n\u001b[32m    857\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cond \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:            \n\u001b[32m--> \u001b[39m\u001b[32m858\u001b[39m     cond_out, _ = \u001b[38;5;28mself\u001b[39m.cond_lstm(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mEmb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcond\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    859\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.proj(torch.cat([x + \u001b[38;5;28mself\u001b[39m.cond_output(cond_out), t, i, time_info], -\u001b[32m1\u001b[39m))    \n\u001b[32m    860\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/projects/AI4Health/notebooks/ibrahimm/Generative-Models/ehr/3_timeautodiff-mvp/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/projects/AI4Health/notebooks/ibrahimm/Generative-Models/ehr/3_timeautodiff-mvp/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m/mnthpc/netapp01/projects/AI4Health/notebooks/ibrahimm/Generative-Models/ehr/3_timeautodiff-mvp/timeautodiff/timeautodiff_v4_efficient_simple.py:278\u001b[39m, in \u001b[36mEmbedding_data_diff.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    276\u001b[39m \u001b[38;5;66;03m# Binary + Discrete Variables\u001b[39;00m\n\u001b[32m    277\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.n_disc != \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m278\u001b[39m     variable_embeddings = \u001b[43m[\u001b[49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_disc\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43membeddings_list\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    279\u001b[39m     x_disc_emb = torch.cat(variable_embeddings, dim=\u001b[32m2\u001b[39m)\n\u001b[32m    280\u001b[39m     x_emb = x_disc_emb\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m/mnthpc/netapp01/projects/AI4Health/notebooks/ibrahimm/Generative-Models/ehr/3_timeautodiff-mvp/timeautodiff/timeautodiff_v4_efficient_simple.py:278\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m    276\u001b[39m \u001b[38;5;66;03m# Binary + Discrete Variables\u001b[39;00m\n\u001b[32m    277\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.n_disc != \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m278\u001b[39m     variable_embeddings = [\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_disc\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m i, embedding \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m.embeddings_list)]\n\u001b[32m    279\u001b[39m     x_disc_emb = torch.cat(variable_embeddings, dim=\u001b[32m2\u001b[39m)\n\u001b[32m    280\u001b[39m     x_emb = x_disc_emb\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/projects/AI4Health/notebooks/ibrahimm/Generative-Models/ehr/3_timeautodiff-mvp/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/projects/AI4Health/notebooks/ibrahimm/Generative-Models/ehr/3_timeautodiff-mvp/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/projects/AI4Health/notebooks/ibrahimm/Generative-Models/ehr/3_timeautodiff-mvp/.venv/lib/python3.11/site-packages/torch/nn/modules/sparse.py:190\u001b[39m, in \u001b[36mEmbedding.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    189\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m190\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    191\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    192\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    193\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    194\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    195\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    196\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    197\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    198\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/projects/AI4Health/notebooks/ibrahimm/Generative-Models/ehr/3_timeautodiff-mvp/.venv/lib/python3.11/site-packages/torch/nn/functional.py:2551\u001b[39m, in \u001b[36membedding\u001b[39m\u001b[34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[39m\n\u001b[32m   2545\u001b[39m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[32m   2546\u001b[39m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[32m   2547\u001b[39m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[32m   2548\u001b[39m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[32m   2549\u001b[39m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[32m   2550\u001b[39m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[32m-> \u001b[39m\u001b[32m2551\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
                        "\u001b[31mOutOfMemoryError\u001b[39m: CUDA out of memory. Tried to allocate 124.00 MiB. GPU 0 has a total capacity of 39.38 GiB of which 22.00 MiB is free. Process 3372021 has 678.00 MiB memory in use. Process 3726096 has 4.51 GiB memory in use. Process 4160385 has 22.46 GiB memory in use. Process 447704 has 798.00 MiB memory in use. Process 1480267 has 8.30 GiB memory in use. Process 1693100 has 928.00 MiB memory in use. Including non-PyTorch memory, this process has 1.71 GiB memory in use. Of the allocated memory 1.04 GiB is allocated by PyTorch, and 177.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
                    ]
                }
            ],
            "source": [
                "synth_data_list = []\n",
                "synth_data_y_list = []\n",
                "\n",
                "\n",
                "\n",
                "n_generations = 2\n",
                "for i in tqdm.notebook.tqdm(range(n_generations), desc=\"Generating Synthetic Data\", leave=True):\n",
                "\n",
                "\n",
                "\n",
                "    _synth_data = tdf_helper.generate_synthetic_data_in_batches(model, cond_train, time_info_train, \n",
                "                                                                       batch_size = 10000)\n",
                "    _synth_data_y = cond_train[:, 0, -1]\n",
                "    synth_data_list.append(_synth_data.cpu().numpy())\n",
                "    synth_data_y_list.append(_synth_data_y.cpu().numpy().reshape(-1,))\n",
                "\n",
                "\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
