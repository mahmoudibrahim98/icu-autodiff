{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKFG-wkL06ed"
      },
      "source": [
        "# 0) Prepare Colab environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "b1UU89ym06ee",
        "outputId": "06eebb7f-4245-416a-9b74-549388a6265c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'icu-autodiff'...\n",
            "remote: Enumerating objects: 100, done.\u001b[K\n",
            "remote: Counting objects: 100% (100/100), done.\u001b[K\n",
            "remote: Compressing objects: 100% (76/76), done.\u001b[K\n",
            "remote: Total 100 (delta 45), reused 71 (delta 22), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (100/100), 466.79 KiB | 9.93 MiB/s, done.\n",
            "Resolving deltas: 100% (45/45), done.\n",
            "/content/icu-autodiff\n",
            "Requirement already satisfied: pandas<2.3.0,>=2.2.2 in /usr/local/lib/python3.11/dist-packages (from -r colab-compatible-requirements.txt (line 2)) (2.2.2)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from -r colab-compatible-requirements.txt (line 3)) (2.0.2)\n",
            "Requirement already satisfied: torch<2.7.0,>=2.6.0 in /usr/local/lib/python3.11/dist-packages (from -r colab-compatible-requirements.txt (line 4)) (2.6.0+cu124)\n",
            "Requirement already satisfied: scikit-learn>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from -r colab-compatible-requirements.txt (line 5)) (1.6.1)\n",
            "Requirement already satisfied: scipy>=1.13.0 in /usr/local/lib/python3.11/dist-packages (from -r colab-compatible-requirements.txt (line 6)) (1.15.3)\n",
            "Requirement already satisfied: matplotlib>=3.7.0 in /usr/local/lib/python3.11/dist-packages (from -r colab-compatible-requirements.txt (line 9)) (3.10.0)\n",
            "Requirement already satisfied: seaborn>=0.13.0 in /usr/local/lib/python3.11/dist-packages (from -r colab-compatible-requirements.txt (line 10)) (0.13.2)\n",
            "Requirement already satisfied: plotly>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from -r colab-compatible-requirements.txt (line 11)) (5.24.1)\n",
            "Requirement already satisfied: tqdm>=4.60.0 in /usr/local/lib/python3.11/dist-packages (from -r colab-compatible-requirements.txt (line 14)) (4.67.1)\n",
            "Requirement already satisfied: rich<14.0.0,>=12.4.4 in /usr/local/lib/python3.11/dist-packages (from -r colab-compatible-requirements.txt (line 15)) (13.9.4)\n",
            "Collecting absl-py>=2.0.0 (from -r colab-compatible-requirements.txt (line 16))\n",
            "  Downloading absl_py-2.3.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: pyarrow<20.0.0,>=14.0.0 in /usr/local/lib/python3.11/dist-packages (from -r colab-compatible-requirements.txt (line 19)) (18.1.0)\n",
            "Requirement already satisfied: fsspec<2025.4.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from -r colab-compatible-requirements.txt (line 20)) (2025.3.2)\n",
            "Requirement already satisfied: packaging<25.0,>=23.2 in /usr/local/lib/python3.11/dist-packages (from -r colab-compatible-requirements.txt (line 23)) (24.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<2.3.0,>=2.2.2->-r colab-compatible-requirements.txt (line 2)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<2.3.0,>=2.2.2->-r colab-compatible-requirements.txt (line 2)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<2.3.0,>=2.2.2->-r colab-compatible-requirements.txt (line 2)) (2025.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<2.7.0,>=2.6.0->-r colab-compatible-requirements.txt (line 4)) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch<2.7.0,>=2.6.0->-r colab-compatible-requirements.txt (line 4)) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<2.7.0,>=2.6.0->-r colab-compatible-requirements.txt (line 4)) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<2.7.0,>=2.6.0->-r colab-compatible-requirements.txt (line 4)) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<2.7.0,>=2.6.0->-r colab-compatible-requirements.txt (line 4))\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<2.7.0,>=2.6.0->-r colab-compatible-requirements.txt (line 4))\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<2.7.0,>=2.6.0->-r colab-compatible-requirements.txt (line 4))\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<2.7.0,>=2.6.0->-r colab-compatible-requirements.txt (line 4))\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch<2.7.0,>=2.6.0->-r colab-compatible-requirements.txt (line 4))\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch<2.7.0,>=2.6.0->-r colab-compatible-requirements.txt (line 4))\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch<2.7.0,>=2.6.0->-r colab-compatible-requirements.txt (line 4))\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch<2.7.0,>=2.6.0->-r colab-compatible-requirements.txt (line 4))\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch<2.7.0,>=2.6.0->-r colab-compatible-requirements.txt (line 4))\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<2.7.0,>=2.6.0->-r colab-compatible-requirements.txt (line 4)) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<2.7.0,>=2.6.0->-r colab-compatible-requirements.txt (line 4)) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<2.7.0,>=2.6.0->-r colab-compatible-requirements.txt (line 4)) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch<2.7.0,>=2.6.0->-r colab-compatible-requirements.txt (line 4))\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<2.7.0,>=2.6.0->-r colab-compatible-requirements.txt (line 4)) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<2.7.0,>=2.6.0->-r colab-compatible-requirements.txt (line 4)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<2.7.0,>=2.6.0->-r colab-compatible-requirements.txt (line 4)) (1.3.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.5.0->-r colab-compatible-requirements.txt (line 5)) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.5.0->-r colab-compatible-requirements.txt (line 5)) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->-r colab-compatible-requirements.txt (line 9)) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->-r colab-compatible-requirements.txt (line 9)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->-r colab-compatible-requirements.txt (line 9)) (4.58.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->-r colab-compatible-requirements.txt (line 9)) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->-r colab-compatible-requirements.txt (line 9)) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->-r colab-compatible-requirements.txt (line 9)) (3.2.3)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly>=5.0.0->-r colab-compatible-requirements.txt (line 11)) (9.1.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich<14.0.0,>=12.4.4->-r colab-compatible-requirements.txt (line 15)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich<14.0.0,>=12.4.4->-r colab-compatible-requirements.txt (line 15)) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=12.4.4->-r colab-compatible-requirements.txt (line 15)) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<2.3.0,>=2.2.2->-r colab-compatible-requirements.txt (line 2)) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<2.7.0,>=2.6.0->-r colab-compatible-requirements.txt (line 4)) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m49.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m46.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m64.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading absl_py-2.3.0-py3-none-any.whl (135 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.7/135.7 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, absl-py, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: absl-py\n",
            "    Found existing installation: absl-py 1.4.0\n",
            "    Uninstalling absl-py-1.4.0:\n",
            "      Successfully uninstalled absl-py-1.4.0\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed absl-py-2.3.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ],
      "source": [
        "# -------------------------------------------------------------------\n",
        "# 📦 1) Clone your repo & cd into it\n",
        "# -------------------------------------------------------------------\n",
        "!git clone https://github.com/mahmoudibrahim98/icu-autodiff.git\n",
        "%cd icu-autodiff\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# 📦 2) Install  project dependencies\n",
        "# -------------------------------------------------------------------\n",
        "\n",
        "!pip install -r colab-compatible-requirements.txt\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# 📦 3) (If your code lives in subfolders) add them to PYTHONPATH\n",
        "# -------------------------------------------------------------------\n",
        "import sys\n",
        "sys.path.append('.')         # or 'src', etc., depending on your layout\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gdown\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HB5d_pwz4rLB",
        "outputId": "ce288624-dc67-4a21-8841-f994b3c9f245"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.11/dist-packages (5.2.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown) (4.13.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from gdown) (3.18.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.11/dist-packages (from gdown) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from gdown) (4.67.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2025.4.26)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (1.7.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import gdown\n",
        "import os\n",
        "os.mkdir('outputs')\n",
        "!gdown --folder https://drive.google.com/drive/folders/1pzJd5mH7nYdd0XMSAsSTopxl1CO0e_em?usp=sharing \\\n",
        "  -O ./outputs\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JsvxXLJ84n9f",
        "outputId": "c44eb7cd-ec1f-4ae6-c429-a758f666b9c9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retrieving folder contents\n",
            "Retrieving folder 1Mkuf8LWglwH9Shm8x3OhVV2pdKusRB6Q mortality24\n",
            "Retrieving folder 10qL9ZLAM1AjzyESAUPdW0_lfg-dpjH4h mimic\n",
            "Retrieving folder 1QLv4VweIZczMuprmdgXZ4nOhyQPsiHJH processed\n",
            "Retrieving folder 1oMnd0qrmPHZVNAuQ__Sljr3Km82KQMyE 20250527153216\n",
            "Processing file 15jgQfH79Szzpuv_3rzghPg7SjKLjvRml metadata.json\n",
            "Processing file 11qC1l6xldyJcJBp1WvNZE0hJhKZ5Hfme X_20250527153216_processed.npz\n",
            "Processing file 1_tFleoDZ-8DS93v5EItGjyKgXR2-Rte1 y_20250527153216_processed.npz\n",
            "Retrieving folder contents completed\n",
            "Building directory structure\n",
            "Building directory structure completed\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=15jgQfH79Szzpuv_3rzghPg7SjKLjvRml\n",
            "To: /content/icu-autodiff/outputs/mortality24/mimic/processed/20250527153216/metadata.json\n",
            "100% 408/408 [00:00<00:00, 2.51MB/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=11qC1l6xldyJcJBp1WvNZE0hJhKZ5Hfme\n",
            "From (redirected): https://drive.google.com/uc?id=11qC1l6xldyJcJBp1WvNZE0hJhKZ5Hfme&confirm=t&uuid=e1300794-e6e5-42af-a554-753e437c641e\n",
            "To: /content/icu-autodiff/outputs/mortality24/mimic/processed/20250527153216/X_20250527153216_processed.npz\n",
            "100% 1.46G/1.46G [00:20<00:00, 71.9MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1_tFleoDZ-8DS93v5EItGjyKgXR2-Rte1\n",
            "To: /content/icu-autodiff/outputs/mortality24/mimic/processed/20250527153216/y_20250527153216_processed.npz\n",
            "100% 2.75M/2.75M [00:00<00:00, 238MB/s]\n",
            "Download completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.mkdir('raw_data')\n",
        "!gdown --folder https://drive.google.com/drive/folders/1x0iEVuudDHcVaqb4HDD8R6Bp9vlIW8Pg?usp=drive_link \\\n",
        "  -O ./daw_data"
      ],
      "metadata": {
        "id": "3-KU0Z1KA5pq",
        "outputId": "00b3883d-8a9b-4cad-c79f-40895884f0a8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retrieving folder contents\n",
            "Retrieving folder 1b06_mXLT4XlF4ydKVvA0KkStwuJppbGy mortality24\n",
            "Retrieving folder 1DVJzb1GFC_IBX987UhyZ6JI4i4ngI8m7 mimic\n",
            "Processing file 1MDX0BQqsd9U1IUyKRVA6dp0NOe3rWrMb attrition.csv\n",
            "Processing file 1fnHRVQCG5uk4J8Ue3Qev-ia2BFsJ43PN dyn.parquet\n",
            "Processing file 1Brvswh8qnFsQNTo6IPC2rHZgD2GRBScO outc.parquet\n",
            "Processing file 1RFfx0nM5kLWjMz_qSXUfNXtYm8Vnkypt sta.parquet\n",
            "Retrieving folder contents completed\n",
            "Building directory structure\n",
            "Building directory structure completed\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1MDX0BQqsd9U1IUyKRVA6dp0NOe3rWrMb\n",
            "To: /content/icu-autodiff/daw_data/mortality24/mimic/attrition.csv\n",
            "100% 417/417 [00:00<00:00, 2.38MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1fnHRVQCG5uk4J8Ue3Qev-ia2BFsJ43PN\n",
            "To: /content/icu-autodiff/daw_data/mortality24/mimic/dyn.parquet\n",
            "100% 13.3M/13.3M [00:00<00:00, 46.5MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Brvswh8qnFsQNTo6IPC2rHZgD2GRBScO\n",
            "To: /content/icu-autodiff/daw_data/mortality24/mimic/outc.parquet\n",
            "100% 236k/236k [00:00<00:00, 126MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1RFfx0nM5kLWjMz_qSXUfNXtYm8Vnkypt\n",
            "To: /content/icu-autodiff/daw_data/mortality24/mimic/sta.parquet\n",
            "100% 779k/779k [00:00<00:00, 172MB/s]\n",
            "Download completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g5YKVafi06ee"
      },
      "source": [
        "# 1) Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v7wRjaUQ06ef",
        "outputId": "36f065fb-b952-4b84-bdee-fa37f837091a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current CUDA device: 0\n",
            "True\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import sys\n",
        "import os\n",
        "# Add the project root directory to the Python path\n",
        "parent_dir = os.path.dirname(os.path.abspath(''))\n",
        "sys.path.append(parent_dir)\n",
        "\n",
        "from datetime import datetime, timedelta\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "# Set the CUDA device to 0\n",
        "torch.cuda.set_device(0)\n",
        "\n",
        "# Verify the current device\n",
        "current_device = torch.cuda.current_device()\n",
        "print(f\"Current CUDA device: {current_device}\")\n",
        "print(torch.cuda.is_available())\n",
        "\n",
        "import data_access.base_loader as base_loader\n",
        "import data_access.ricu_loader as ricu_loader\n",
        "from absl import flags\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZRhb2JFH06ef",
        "outputId": "f7f2b13f-ec91-41a7-d497-b0f03671892b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/icu-autodiff/data_access/base_loader.py:596: UserWarning: This will split the data into train, val, test sets stratified on outcome and demographics_to_stratify_on, according to the train_fraction and val_fraction\n",
            "  warnings.warn(\"This will split the data into train, val, test sets stratified on outcome and demographics_to_stratify_on, according to the train_fraction and val_fraction\")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['X_original_train', 'X_original_val', 'X_original_test', 'X_imputed_train', 'X_imputed_val', 'X_imputed_test', 'm_train', 'm_val', 'm_test', 'delta_t_train', 'delta_t_val', 'delta_t_test', 'feature_names'])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "# splitting parameters\n",
        "train_fraction = 0.45\n",
        "val_fraction = 0.1\n",
        "oracle_fraction = 0\n",
        "oracle_min = 100\n",
        "intersectional_min_threshold = 100\n",
        "intersectional_max_threshold = 1000\n",
        "\n",
        "\n",
        "# # data parameters\n",
        "data_name = 'mimic' # 'mimic' 'eicu'\n",
        "task_name = 'mortality24' # 'aki' 'kidney_function' 'los' 'los_24' 'mortality24'\n",
        "static_var = 'ethnicity'\n",
        "features = None\n",
        "ricu_dataset_path = f'raw_data/{task_name}/{data_name}'\n",
        "processed_output_path = f'outputs/{task_name}/{data_name}/processed/'\n",
        "intermed_output_path = f'outputs/{task_name}/{data_name}/intermed/'\n",
        "seed = 0\n",
        "\n",
        "simple_imputation = True\n",
        "mode = 'processed'\n",
        "processed_data_timestamp = '20250527153216'  # change this to the timestamp of the processed data\n",
        "intermed_data_timestamp = None\n",
        "\n",
        "standardize = False\n",
        "save_intermed_data = True\n",
        "save_processed_data = True\n",
        "split = True\n",
        "stratify =  False\n",
        "intersectional = False\n",
        "\n",
        "if split == False:\n",
        "    split_text = 'No Split'\n",
        "else:\n",
        "    split_text = 'Split'\n",
        "data_params = {\n",
        "    'processed_data_timestamp':processed_data_timestamp,\n",
        "    'task_name': task_name,\n",
        "    'data_name': data_name,\n",
        "    'train_fraction': train_fraction,\n",
        "    'val_fraction': val_fraction,\n",
        "    'holdout_fraction': 1 - train_fraction - val_fraction,\n",
        "    'oracle_fraction': oracle_fraction,\n",
        "    'oracle_min': oracle_min,\n",
        "    'intersectional_min_threshold': intersectional_min_threshold,\n",
        "    'intersectional_max_threshold': intersectional_max_threshold,\n",
        "    'split': split_text,\n",
        "    'standardize' : standardize,\n",
        "}\n",
        "\n",
        "loader = ricu_loader.RicuLoader(seed, task_name, data_name,static_var,ricu_dataset_path,simple_imputation,\n",
        "                                    features, processed_output_path,intermed_output_path)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "X_dict_tf, y_dict, static = loader.get_data(\n",
        "    mode='processed',\n",
        "    train_fraction=train_fraction,\n",
        "    val_fraction=val_fraction,\n",
        "    oracle_fraction=oracle_fraction,\n",
        "    oracle_min=oracle_min,\n",
        "    intersectional_min_threshold=intersectional_min_threshold,\n",
        "    intersectional_max_threshold=intersectional_max_threshold,\n",
        "    stratify=stratify,\n",
        "    intersectional=intersectional,\n",
        "    save_intermed_data=False,\n",
        "    save_processed_data=False,\n",
        "    demographics_to_stratify_on = ['age_group','ethnicity','gender'],\n",
        "    processed_timestamp=processed_data_timestamp\n",
        ")\n",
        "\n",
        "if not isinstance(X_dict_tf, dict):\n",
        "    X_dict_tf = {file: X_dict_tf[file] for file in X_dict_tf.files}\n",
        "    y_dict = {file: y_dict[file] for file in y_dict.files}\n",
        "\n",
        "X_dict_tf.keys()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UzHu5GCF06ef"
      },
      "source": [
        "# 2) Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "D1PhVWHF06ef"
      },
      "outputs": [],
      "source": [
        "# Add the project root directory to the Python path\n",
        "import sys\n",
        "import os\n",
        "parent_dir = os.path.dirname(os.path.abspath(''))\n",
        "sys.path.append(parent_dir)\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "import data_access.base_loader as base_loader\n",
        "import data_access.ricu_loader as ricu_loader\n",
        "from datetime import datetime\n",
        "import wandb\n",
        "import ast\n",
        "import logging\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "import timeautodiff.processing_simple as processing\n",
        "import timeautodiff.helper_simple as tdf_helper\n",
        "import timeautodiff.timeautodiff_v4_efficient_simple as timeautodiff"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VOvxdnE306eg"
      },
      "source": [
        "## 2.1) Data Preperation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7V3-3h9906eg",
        "outputId": "bdb85cdb-b386-491b-928c-3fdcd4e3ea6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X train: (17157, 48, 25)\n",
            "Shape of X Holdout: (17157, 48, 25)\n",
            "Shape of X Holdout val: (3812, 48, 25)\n",
            "Shape of y train: (17157,)\n",
            "Shape of y Holdout: (17157,)\n",
            "Shape of y Holdout val: (3812,)\n",
            "Shape of c train: (17157, 3)\n",
            "Shape of c Holdout: (17157, 3)\n",
            "Shape of c Holdout val: (3812, 3)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# most_important_features = [19, 27, 17, 35, 22, 44, 42, 43, 37, 26]\n",
        "X_train = X_dict_tf['X_imputed_train'][:,:,:]\n",
        "X_holdout = X_dict_tf['X_imputed_test'][:,:,:]\n",
        "X_holdout_val = X_dict_tf['X_imputed_val'][:,:,:]\n",
        "\n",
        "m_train = X_dict_tf['m_train'][:,:,:]\n",
        "m_holdout = X_dict_tf['m_test'][:,:,:]\n",
        "m_holdout_val = X_dict_tf['m_val'][:,:,:]\n",
        "\n",
        "feature_names = X_dict_tf['feature_names'][:]\n",
        "y_train = y_dict['y_train'][:]\n",
        "y_holdout = y_dict['y_test'][:]\n",
        "y_holdout_val = y_dict['y_val'][:]\n",
        "\n",
        "\n",
        "static_feature_to_include = ['ethnicity','gender','age_group']\n",
        "static_features_to_include_indices = sorted([y_dict['feature_names'].tolist().index(include)  for include in static_feature_to_include])\n",
        "c_train = y_dict['c_train'][:,static_features_to_include_indices]\n",
        "c_holdout = y_dict['c_test'][:,static_features_to_include_indices]\n",
        "c_holdout_val = y_dict['c_val'][:,static_features_to_include_indices]\n",
        "\n",
        "cond_names = y_dict['feature_names'][static_features_to_include_indices]\n",
        "\n",
        "\n",
        "\n",
        "top10_important_features = [19, 27, 17, 35, 22, 44, 42, 43, 37, 26]\n",
        "top3_important_features = [44,42,43]\n",
        "top6_important_features = [42, 22, 27, 35, 43, 17]\n",
        "\n",
        "important_features_names = X_dict_tf['feature_names'][top10_important_features]\n",
        "important_features_names\n",
        "\n",
        "X_train_10 = processing.normalize_and_reshape(X_train)\n",
        "X_train_10 = X_train_10[:,:,top10_important_features]\n",
        "\n",
        "print('Shape of X train:', X_train.shape)\n",
        "print('Shape of X Holdout:', X_holdout.shape)\n",
        "print('Shape of X Holdout val:', X_holdout_val.shape)\n",
        "\n",
        "print('Shape of y train:', y_train.shape)\n",
        "print('Shape of y Holdout:', y_holdout.shape)\n",
        "print('Shape of y Holdout val:', y_holdout_val.shape)\n",
        "\n",
        "print('Shape of c train:', c_train.shape)\n",
        "print('Shape of c Holdout:', c_holdout.shape)\n",
        "print('Shape of c Holdout val:', c_holdout_val.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n8ivHYKF06eg",
        "outputId": "26ccb842-724b-46d0-83e4-794b36cb8017"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of the response data: torch.Size([17157, 25, 10])\n",
            "Shape of the condition data: torch.Size([17157, 25, 4])\n"
          ]
        }
      ],
      "source": [
        "\n",
        "################################################################################################################\n",
        "################################################################################################################\n",
        "################################################################################################################\n",
        "                                                    # Prepare Data for Training #\n",
        "################################################################################################################\n",
        "################################################################################################################\n",
        "################################################################################################################\n",
        "\n",
        "\n",
        "metadata = f\"{data_name}_{task_name}\"\n",
        "\n",
        "process_data = True\n",
        "load_data = False\n",
        "train_models = True\n",
        "train_auto = True\n",
        "train_diff = True\n",
        "load_model = False\n",
        "# processed_data_timestamp = '20241203_130537_10features'\n",
        "\n",
        "model_version = 'v4_efficient_simple'\n",
        "\n",
        "\n",
        "EXP_PATH = os.path.join(os.getcwd(), 'outputs')\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "gen_model = 'TimeAutoDiff'\n",
        "output_dir = f'outputs/{task_name}/{data_name}/{gen_model}/{timestamp}_{len(important_features_names)}features_{model_version}_{metadata}'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "numerical_processing = 'normalize'\n",
        "\n",
        "\n",
        "\n",
        "# prorcess data for training of generators\n",
        "processed_X, processed_y, processed_c, time_info = processing.process_data_for_synthesizer(X_train, y_train, c_train, top10_important_features)\n",
        "cond = torch.concatenate((processed_c, processed_y), axis=2)\n",
        "response = processed_X\n",
        "response = response.float()\n",
        "time_info = time_info.float()\n",
        "\n",
        "\n",
        "metadata = {\n",
        "    'model_version': model_version,\n",
        "    'genmodel_timestamp': timestamp,\n",
        "    'important_features_names': important_features_names.tolist(),\n",
        "    'number of features': len(important_features_names),\n",
        "    'seq_len': processed_X.shape[1],\n",
        "    'seed': seed,\n",
        "    'patient_length': processed_X.shape[0],\n",
        "    'numerical_processing': numerical_processing,\n",
        "}\n",
        "metadata.update(data_params)\n",
        "metadata_path = os.path.join(output_dir, 'metadata.json')\n",
        "with open(metadata_path, 'w') as f:\n",
        "    json.dump(metadata, f, indent=4)\n",
        "\n",
        "\n",
        "################################################################################################################\n",
        "# Checking Processed Data #\n",
        "################################################################################################################\n",
        "\n",
        "print(f\"Shape of the response data: {processed_X.shape}\")\n",
        "print(f\"Shape of the condition data: {cond.shape}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9q8IFIq06eh"
      },
      "source": [
        "## 2.3) Training Auto encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69,
          "referenced_widgets": [
            "a8b5e2c5ed71472383ef8e919259fa9c",
            "447120f232a04ec9a860df33f310b591"
          ]
        },
        "id": "yZhP3YMz06eh",
        "outputId": "55c17bff-c38a-4862-fd85-12f537ddae9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New parameters appended successfully.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a8b5e2c5ed71472383ef8e919259fa9c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Latent features saved successfully.\n"
          ]
        }
      ],
      "source": [
        "################################################################################################################\n",
        "################################################################################################################\n",
        "################################################################################################################\n",
        "                                                    # Training #\n",
        "################################################################################################################\n",
        "################################################################################################################\n",
        "################################################################################################################\n",
        "efficient = True\n",
        "auto_mmd_weight = 0\n",
        "auto_consistency_weight = 0\n",
        "diff_mmd_weight = 0\n",
        "diff_consistency_weight = 0\n",
        "full_metadata = f'auto_mmd_{auto_mmd_weight}_auto_cons_{auto_consistency_weight}_diff_mmd_{diff_mmd_weight}_diff_cons_{diff_consistency_weight}'\n",
        "# metadata = f'{id}'\n",
        "\n",
        "use_wandb = False\n",
        "\n",
        "################################################################################################################\n",
        "# Defining Model Parameters #\n",
        "################################################################################################################\n",
        "if train_models:\n",
        "    VAE_training = 200\n",
        "    diff_training = 200\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    ###### Auto-encoder Parameters ######\n",
        "    n_epochs = VAE_training; eps = 1e-5\n",
        "    weight_decay = 1e-6; lr = 2e-4; hidden_size = 200; num_layers = 2; batch_size = 100\n",
        "    channels = 64; min_beta = 1e-5; max_beta = 0.1; emb_dim = 128; time_dim = time_info.shape[2];  lat_dim = response.shape[2]; threshold = 1\n",
        "\n",
        "    if lat_dim > response.shape[2]:\n",
        "        raise ValueError(\"lat_dim should be less than the number of important features.\")\n",
        "\n",
        "    ###### Diffusion Parameters ######\n",
        "    n_epochs = diff_training; hidden_dim = 200; num_layers = 2; diffusion_steps = 100;\n",
        "\n",
        "\n",
        "    new_params = {\n",
        "        \"VAE_training\": VAE_training,\n",
        "        \"diff_training\": diff_training,\n",
        "        \"device\": str(device),\n",
        "        \"imputation strategy\": \"randomly select from imputed patients.\", # \"drop missing values\"\n",
        "        \"eps\" : eps,\n",
        "        \"auto_weight_decay\" : weight_decay,\n",
        "        \"auto_lr\" : lr,\n",
        "        \"auto_hidden_size\" : hidden_size,\n",
        "        \"auto_num_layers\" : num_layers,\n",
        "        \"auto_batch_size\" : batch_size,\n",
        "        \"auto_channels\" : channels,\n",
        "        \"auto_min_beta\" : min_beta,\n",
        "        \"auto_max_beta\" : max_beta,\n",
        "        \"auto_emb_dim\" : emb_dim,\n",
        "        \"auto_time_dim\" : time_dim,\n",
        "        \"auto_lat_dim\" : lat_dim,\n",
        "        \"auto_threshold\" : threshold,\n",
        "        \"diff_hidden_dim\" : hidden_dim,\n",
        "        \"diffusion_steps\" : diffusion_steps,\n",
        "        \"diff_num_layers\" : num_layers,\n",
        "        \"auto_mmd_weight\" : auto_mmd_weight,\n",
        "        \"auto_consistency_weight\" : auto_consistency_weight,\n",
        "        \"diff_mmd_weight\" : diff_mmd_weight,\n",
        "        \"diff_consistency_weight\" : diff_consistency_weight\n",
        "    }\n",
        "\n",
        "    # Call the method\n",
        "    tdf_helper.append_new_params_to_metadata(output_dir, new_params)\n",
        "\n",
        "    # Path to the metadata JSON file\n",
        "    metadata_path = os.path.join(output_dir, 'metadata.json')\n",
        "    # Read the existing JSON file\n",
        "    with open(metadata_path, 'r') as f:\n",
        "        metadata = json.load(f)\n",
        "\n",
        "    # Extract the parameters\n",
        "    patient_length = metadata.get('patient_length')\n",
        "    imputation_strategy = metadata.get('imputation strategy')\n",
        "    number_of_features = metadata.get('number of features')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    ################################################################################################################\n",
        "    # WANDB Initialization #\n",
        "    ################################################################################################################\n",
        "    if use_wandb:\n",
        "        config = dict(\n",
        "            model = \"TimeAutoDiff\",\n",
        "            patient_length = patient_length,\n",
        "            imputation_strategy = imputation_strategy,\n",
        "            number_of_features = number_of_features,\n",
        "            epochs_VAE = VAE_training,\n",
        "            epochs_diffusion = diff_training,\n",
        "            pred_task = task_name,\n",
        "            data_name = data_name,\n",
        "        )\n",
        "\n",
        "        use_cuda = torch.cuda.is_available()\n",
        "        wandb.init(\n",
        "            project = 'TimeAutoDiff',\n",
        "            config = config,\n",
        "            name = output_dir.split('/')[-1],\n",
        "        )\n",
        "\n",
        "    ################################################################################################################\n",
        "    # Auto-encoder Training #\n",
        "    ################################################################################################################\n",
        "if train_auto:\n",
        "    torch.cuda.empty_cache()\n",
        "    if efficient:\n",
        "        ds = timeautodiff.train_autoencoder(response, channels, hidden_size, num_layers, lr, weight_decay, n_epochs,\n",
        "                                                      batch_size, min_beta, max_beta, emb_dim, time_dim, lat_dim, device,output_dir, checkpoints=True,\n",
        "                                                    mmd_weight = auto_mmd_weight, consistency_weight = auto_consistency_weight, use_wandb=use_wandb)\n",
        "    # Save Autoencoder\n",
        "    ae = ds[0]\n",
        "    ae.save_model(os.path.join(output_dir, 'autoencoder'))\n",
        "    # Save latent features\n",
        "    latent_features = ds[1]\n",
        "    processing.save_tensor(latent_features,output_dir, 'latent_features.pt')\n",
        "    print(\"Latent features saved successfully.\")\n",
        "else:\n",
        "    latent_features = torch.load(os.path.join(output_dir, 'latent_features.pt'))\n",
        "    ae = timeautodiff.DeapStack.load_model(os.path.join(output_dir, 'autoencoder.pt'))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p8izD1ah06eh"
      },
      "source": [
        "## 2.3) Training Diffusion Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51,
          "referenced_widgets": [
            "1dc450639b174097b0789f1861aa68ab",
            "d231e12d235141088c4fc225f00bbac0"
          ]
        },
        "id": "y3zTtBJW06eh",
        "outputId": "2030809d-02b5-4f8f-f481-f32e86f66cd2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New parameters appended successfully.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1dc450639b174097b0789f1861aa68ab"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "################################################################################################################\n",
        "# Diffusion Training #\n",
        "################################################################################################################\n",
        "if train_diff:\n",
        "    num_classes = len(latent_features)\n",
        "\n",
        "    new_params = {\n",
        "        \"diff_num_classes\" : num_classes,\n",
        "    }\n",
        "    # Call the method\n",
        "    tdf_helper.append_new_params_to_metadata(output_dir, new_params)\n",
        "\n",
        "    diff = timeautodiff.train_diffusion(latent_features, cond, time_info, hidden_dim, num_layers, diffusion_steps, n_epochs,output_dir,\n",
        "                                        checkpoints = True, num_classes = num_classes,\n",
        "                                        mmd_weight = diff_mmd_weight, consistency_weight = diff_consistency_weight, use_wandb=use_wandb)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kinzgDoX06eh"
      },
      "source": [
        "# 3) Generating Synthetic Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "topGKjKh06eh"
      },
      "source": [
        "## 3.1) Model Loading (In case not loaded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YAU2ihzr06eh",
        "outputId": "5bcb37b5-5ad5-48bc-e5ce-8edede3578e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "############ Evaluating timestamp 20250527_135807_10features_v4_efficient_simple_mimic_mortality24: ############\n",
            "Latent features loaded successfully.\n",
            "Latent features shape: torch.Size([17157, 25, 10])\n"
          ]
        }
      ],
      "source": [
        "################################################################################################################\n",
        "# Model Evaluation\n",
        "################################################################################################################\n",
        "output_dir = f'outputs/{task_name}/{data_name}/TimeAutoDiff/'\n",
        "latest_diffusion_timestamp = sorted(os.listdir(output_dir))[-1]\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"############ Evaluating timestamp {latest_diffusion_timestamp}: ############\")\n",
        "\n",
        "model = tdf_helper.load_models_only(latest_diffusion_timestamp, task_name, data_name)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0GKkOvKO06ei"
      },
      "source": [
        "## 3.2) Sampling from Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tqdm"
      ],
      "metadata": {
        "id": "27z9_BOBCwxp",
        "outputId": "0fa3c2f9-df5b-4f58-867f-60f6a2b991f6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "EiUklq-106ei"
      },
      "outputs": [],
      "source": [
        "response_train, outcome_train, static_train, time_info_train = processing.process_data_for_synthesizer(X_train, y_train, c_train, top10_important_features)\n",
        "cond_train = torch.concatenate((static_train, outcome_train), axis=2)\n",
        "response_train = response_train.float()\n",
        "time_info_train = time_info_train.float()\n",
        "cond_train = cond_train.float()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bMiSkAC206ei",
        "outputId": "3bb56fbb-7d7c-4454-a26d-108c61962a78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating Synthetic Data: 100%|██████████| 2/2 [03:41<00:00, 110.67s/it]\n"
          ]
        }
      ],
      "source": [
        "synth_data_list = []\n",
        "synth_data_y_list = []\n",
        "\n",
        "\n",
        "\n",
        "n_generations = 2\n",
        "for i in tqdm(range(n_generations), desc=\"Generating Synthetic Data\", leave=True):\n",
        "\n",
        "\n",
        "\n",
        "    _synth_data = tdf_helper.generate_synthetic_data_in_batches(model, cond_train, time_info_train,\n",
        "                                                                       batch_size = 10000)\n",
        "    _synth_data_y = cond_train[:, 0, -1]\n",
        "    synth_data_list.append(_synth_data.cpu().numpy())\n",
        "    synth_data_y_list.append(_synth_data_y.cpu().numpy().reshape(-1,))\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a8b5e2c5ed71472383ef8e919259fa9c": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_447120f232a04ec9a860df33f310b591",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "Epoch 195/200 - Loss: 0.0061 \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m \u001b[35m 98%\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Epoch 195/200 - Loss: 0.0061 <span style=\"color: #f92672; text-decoration-color: #f92672\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span><span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">╺</span> <span style=\"color: #800080; text-decoration-color: #800080\"> 98%</span> <span style=\"color: #008080; text-decoration-color: #008080\">0:00:01</span>\n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "447120f232a04ec9a860df33f310b591": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1dc450639b174097b0789f1861aa68ab": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_d231e12d235141088c4fc225f00bbac0",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "Epoch 195/200 - Loss: 0.2732 \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m \u001b[35m 98%\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Epoch 195/200 - Loss: 0.2732 <span style=\"color: #f92672; text-decoration-color: #f92672\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span><span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">╺</span> <span style=\"color: #800080; text-decoration-color: #800080\"> 98%</span> <span style=\"color: #008080; text-decoration-color: #008080\">0:00:01</span>\n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "d231e12d235141088c4fc225f00bbac0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}