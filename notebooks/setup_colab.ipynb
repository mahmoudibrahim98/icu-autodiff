{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0) Prepare Colab environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------\n",
    "# ðŸ“¦ 1) Clone your repo & cd into it\n",
    "# -------------------------------------------------------------------\n",
    "!git clone https://github.com/mahmoudibrahim98/icu-autodiff.git\n",
    "%cd icu-autodiff\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# ðŸ“¦ 2) Install  project dependencies\n",
    "# -------------------------------------------------------------------\n",
    "\n",
    "!pip install -r colab-compatible-requirements.txt\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# ðŸ“¦ 3) (If your code lives in subfolders) add them to PYTHONPATH\n",
    "# -------------------------------------------------------------------\n",
    "import sys\n",
    "sys.path.append('.')         # or 'src', etc., depending on your layout\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# ðŸ“¦ 4) (Optional) Mount Drive for large data\n",
    "# -------------------------------------------------------------------\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')\n",
    "#DATA_DIR = '/content/drive/MyDrive/yourproject/data'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Data Preparation (Needed once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "import os\n",
    "# Add the project root directory to the Python path\n",
    "parent_dir = os.path.dirname(os.path.abspath(''))\n",
    "sys.path.append(parent_dir)\n",
    "                            \n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Set the CUDA device to 0\n",
    "torch.cuda.set_device(0)\n",
    "\n",
    "# Verify the current device\n",
    "current_device = torch.cuda.current_device()\n",
    "print(f\"Current CUDA device: {current_device}\")\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "import data_access.base_loader as base_loader\n",
    "import data_access.ricu_loader as ricu_loader\n",
    "from absl import flags\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# splitting parameters\n",
    "train_fraction = 0.45\n",
    "val_fraction = 0.1\n",
    "oracle_fraction = 0\n",
    "oracle_min = 100\n",
    "intersectional_min_threshold = 100\n",
    "intersectional_max_threshold = 1000\n",
    "\n",
    "\n",
    "# # data parameters\n",
    "data_name = 'mimic' # 'mimic' 'eicu'\n",
    "task_name = 'mortality24' # 'aki' 'kidney_function' 'los' 'los_24' 'mortality24' \n",
    "static_var = 'ethnicity'\n",
    "features = None\n",
    "ricu_dataset_path = f'../raw_data/{task_name}/{data_name}'\n",
    "processed_output_path = f'outputs/{task_name}/{data_name}/processed/'\n",
    "intermed_output_path = f'outputs/{task_name}/{data_name}/intermed/'\n",
    "\n",
    "seed = 0\n",
    "\n",
    "simple_imputation = True\n",
    "mode = 'raw'\n",
    "intermed_data_timestamp = None\n",
    "\n",
    "standardize = False\n",
    "save_intermed_data = True\n",
    "save_processed_data = True\n",
    "\n",
    "\n",
    "split = True # will split into train, val, test, stratified on outcome and demographics_to_stratify_on\n",
    "stratify =  False\n",
    "intersectional = False\n",
    "\n",
    "if split == False:\n",
    "    split_text = 'No Split'\n",
    "\n",
    "'''\n",
    "Two modes of operation:\n",
    "\n",
    "'''\n",
    "\n",
    "loader = ricu_loader.RicuLoader(seed, task_name, data_name,static_var,ricu_dataset_path,simple_imputation,\n",
    "                                    features, processed_output_path,intermed_output_path)\n",
    "\n",
    "\n",
    "if mode == 'raw':\n",
    "    # Create directories if they do not exist\n",
    "    if save_intermed_data:\n",
    "        os.makedirs(intermed_output_path, exist_ok=True)\n",
    "    if save_processed_data:\n",
    "        os.makedirs(processed_output_path, exist_ok=True)\n",
    "        \n",
    "    X_dict_tf, y_dict, static = loader.get_data(mode='raw', train_fraction=train_fraction, val_fraction=val_fraction, oracle_fraction=oracle_fraction, \n",
    "                                                oracle_min=oracle_min, intersectional_min_threshold=intersectional_min_threshold,\n",
    "                                                intersectional_max_threshold=intersectional_max_threshold,\n",
    "                                                standardize=standardize,\n",
    "                                                stratify=stratify, intersectional=intersectional, split = split,\n",
    "                                                save_intermed_data=save_intermed_data, save_processed_data=save_processed_data,\n",
    "                                                demographics_to_stratify_on = ['age_group','ethnicity','gender'])\n",
    "else:\n",
    "    raise ValueError(\"Invalid mode specified. Choose 'raw', 'processed', or 'intermediate'.\")\n",
    "\n",
    "if not isinstance(X_dict_tf, dict):\n",
    "    X_dict_tf = {file: X_dict_tf[file] for file in X_dict_tf.files}\n",
    "    y_dict = {file: y_dict[file] for file in y_dict.files}\n",
    "\n",
    "X_dict_tf.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Add the project root directory to the Python path\n",
    "import sys\n",
    "import os\n",
    "parent_dir = os.path.dirname(os.path.abspath(''))\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "import numpy as np\n",
    "import torch \n",
    "\n",
    "import data_access.base_loader as base_loader\n",
    "import data_access.ricu_loader as ricu_loader\n",
    "from datetime import datetime\n",
    "import wandb\n",
    "import ast\n",
    "import logging\n",
    "import json\n",
    "\n",
    "import timeautodiff.processing_simple as processing\n",
    "import timeautodiff.helper_simple as tdf_helper\n",
    "import timeautodiff.timeautodiff_v4_efficient_simple as timeautodiff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1) Data Preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# most_important_features = [19, 27, 17, 35, 22, 44, 42, 43, 37, 26]\n",
    "X_train = X_dict_tf['X_imputed_train'][:,:,:]\n",
    "X_holdout = X_dict_tf['X_imputed_test'][:,:,:]\n",
    "X_holdout_val = X_dict_tf['X_imputed_val'][:,:,:]\n",
    "\n",
    "m_train = X_dict_tf['m_train'][:,:,:]\n",
    "m_holdout = X_dict_tf['m_test'][:,:,:]\n",
    "m_holdout_val = X_dict_tf['m_val'][:,:,:]\n",
    "\n",
    "feature_names = X_dict_tf['feature_names'][:]\n",
    "y_train = y_dict['y_train'][:]\n",
    "y_holdout = y_dict['y_test'][:]\n",
    "y_holdout_val = y_dict['y_val'][:]\n",
    "\n",
    "\n",
    "static_feature_to_include = ['ethnicity','gender','age_group']\n",
    "static_features_to_include_indices = sorted([y_dict['feature_names'].tolist().index(include)  for include in static_feature_to_include])\n",
    "c_train = y_dict['c_train'][:,static_features_to_include_indices]\n",
    "c_holdout = y_dict['c_test'][:,static_features_to_include_indices]\n",
    "c_holdout_val = y_dict['c_val'][:,static_features_to_include_indices]\n",
    "\n",
    "cond_names = y_dict['feature_names'][static_features_to_include_indices]\n",
    "\n",
    "\n",
    "\n",
    "top10_important_features = [19, 27, 17, 35, 22, 44, 42, 43, 37, 26]\n",
    "top3_important_features = [44,42,43]\n",
    "top6_important_features = [42, 22, 27, 35, 43, 17]\n",
    "\n",
    "important_features_names = X_dict_tf['feature_names'][top10_important_features]\n",
    "important_features_names\n",
    "\n",
    "X_train_10 = processing.normalize_and_reshape(X_train)\n",
    "X_train_10 = X_train_10[:,:,top10_important_features]\n",
    "\n",
    "print('Shape of X train:', X_train.shape)\n",
    "print('Shape of X Holdout:', X_holdout.shape)\n",
    "print('Shape of X Holdout val:', X_holdout_val.shape)\n",
    "\n",
    "print('Shape of y train:', y_train.shape)\n",
    "print('Shape of y Holdout:', y_holdout.shape)\n",
    "print('Shape of y Holdout val:', y_holdout_val.shape)\n",
    "\n",
    "print('Shape of c train:', c_train.shape)\n",
    "print('Shape of c Holdout:', c_holdout.shape)\n",
    "print('Shape of c Holdout val:', c_holdout_val.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "################################################################################################################\n",
    "################################################################################################################\n",
    "################################################################################################################\n",
    "                                                    # Prepare Data for Training #\n",
    "################################################################################################################\n",
    "################################################################################################################\n",
    "################################################################################################################\n",
    "\n",
    "\n",
    "metadata = f\"{data_name}_{task_name}\"\n",
    "\n",
    "process_data = True\n",
    "load_data = False\n",
    "train_models = True\n",
    "train_auto = True\n",
    "train_diff = True\n",
    "load_model = False\n",
    "# processed_data_timestamp = '20241203_130537_10features'\n",
    "\n",
    "model_version = 'v4_efficient_simple'\n",
    "\n",
    "    \n",
    "EXP_PATH = os.path.join(os.getcwd(), 'outputs')\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "gen_model = 'TimeAutoDiff'\n",
    "output_dir = f'outputs/{task_name}/{data_name}/{gen_model}/{timestamp}_{len(important_features_names)}features_{model_version}_{metadata}'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "numerical_processing = 'normalize'\n",
    "\n",
    "\n",
    "    \n",
    "# prorcess data for training of generators\n",
    "processed_X, processed_y, processed_c, time_info = processing.process_data_for_synthesizer(X_train, y_train, c_train, top10_important_features)\n",
    "cond = torch.concatenate((processed_c, processed_y), axis=2)\n",
    "response = processed_X\n",
    "response = response.float()\n",
    "time_info = time_info.float()\n",
    "\n",
    "\n",
    "metadata = {\n",
    "    'model_version': model_version,\n",
    "    'genmodel_timestamp': timestamp,\n",
    "    'important_features_names': important_features_names.tolist(),\n",
    "    'number of features': len(important_features_names),\n",
    "    'seq_len': processed_X.shape[1],\n",
    "    'seed': seed,\n",
    "    'patient_length': processed_X.shape[0],\n",
    "    'numerical_processing': numerical_processing,\n",
    "}\n",
    "metadata.update(data_params)\n",
    "metadata_path = os.path.join(output_dir, 'metadata.json')\n",
    "with open(metadata_path, 'w') as f:\n",
    "    json.dump(metadata, f, indent=4)\n",
    "    \n",
    "    \n",
    "################################################################################################################\n",
    "# Checking Processed Data #\n",
    "################################################################################################################\n",
    "\n",
    "print(f\"Shape of the response data: {processed_X.shape}\")\n",
    "print(f\"Shape of the condition data: {cond.shape}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3) Training Auto encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "################################################################################################################\n",
    "################################################################################################################\n",
    "################################################################################################################\n",
    "                                                    # Training #\n",
    "################################################################################################################\n",
    "################################################################################################################\n",
    "################################################################################################################\n",
    "efficient = True\n",
    "auto_mmd_weight = 0\n",
    "auto_consistency_weight = 0\n",
    "diff_mmd_weight = 0\n",
    "diff_consistency_weight = 0\n",
    "full_metadata = f'auto_mmd_{auto_mmd_weight}_auto_cons_{auto_consistency_weight}_diff_mmd_{diff_mmd_weight}_diff_cons_{diff_consistency_weight}'\n",
    "# metadata = f'{id}'\n",
    "\n",
    "use_wandb = False\n",
    "\n",
    "################################################################################################################\n",
    "# Defining Model Parameters #\n",
    "################################################################################################################\n",
    "if train_models:\n",
    "    VAE_training = 200\n",
    "    diff_training = 200\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    ###### Auto-encoder Parameters ######\n",
    "    n_epochs = VAE_training; eps = 1e-5\n",
    "    weight_decay = 1e-6; lr = 2e-4; hidden_size = 200; num_layers = 2; batch_size = 100\n",
    "    channels = 64; min_beta = 1e-5; max_beta = 0.1; emb_dim = 128; time_dim = time_info.shape[2];  lat_dim = response.shape[2]; threshold = 1\n",
    "\n",
    "    if lat_dim > response.shape[2]:\n",
    "        raise ValueError(\"lat_dim should be less than the number of important features.\")\n",
    "\n",
    "    ###### Diffusion Parameters ######\n",
    "    n_epochs = diff_training; hidden_dim = 200; num_layers = 2; diffusion_steps = 100;\n",
    "\n",
    "\n",
    "    new_params = {\n",
    "        \"VAE_training\": VAE_training,\n",
    "        \"diff_training\": diff_training,\n",
    "        \"device\": str(device),\n",
    "        \"imputation strategy\": \"randomly select from imputed patients.\", # \"drop missing values\"\n",
    "        \"eps\" : eps,\n",
    "        \"auto_weight_decay\" : weight_decay,\n",
    "        \"auto_lr\" : lr,\n",
    "        \"auto_hidden_size\" : hidden_size,\n",
    "        \"auto_num_layers\" : num_layers,\n",
    "        \"auto_batch_size\" : batch_size,\n",
    "        \"auto_channels\" : channels,\n",
    "        \"auto_min_beta\" : min_beta,\n",
    "        \"auto_max_beta\" : max_beta,\n",
    "        \"auto_emb_dim\" : emb_dim,\n",
    "        \"auto_time_dim\" : time_dim,\n",
    "        \"auto_lat_dim\" : lat_dim,\n",
    "        \"auto_threshold\" : threshold,\n",
    "        \"diff_hidden_dim\" : hidden_dim,\n",
    "        \"diffusion_steps\" : diffusion_steps,\n",
    "        \"diff_num_layers\" : num_layers,\n",
    "        \"auto_mmd_weight\" : auto_mmd_weight,\n",
    "        \"auto_consistency_weight\" : auto_consistency_weight,\n",
    "        \"diff_mmd_weight\" : diff_mmd_weight,\n",
    "        \"diff_consistency_weight\" : diff_consistency_weight    \n",
    "    }   \n",
    "\n",
    "    # Call the method\n",
    "    tdf_helper.append_new_params_to_metadata(output_dir, new_params)\n",
    "\n",
    "    # Path to the metadata JSON file\n",
    "    metadata_path = os.path.join(output_dir, 'metadata.json')\n",
    "    # Read the existing JSON file\n",
    "    with open(metadata_path, 'r') as f:\n",
    "        metadata = json.load(f)\n",
    "\n",
    "    # Extract the parameters\n",
    "    patient_length = metadata.get('patient_length')\n",
    "    imputation_strategy = metadata.get('imputation strategy')\n",
    "    number_of_features = metadata.get('number of features')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ################################################################################################################\n",
    "    # WANDB Initialization #\n",
    "    ################################################################################################################\n",
    "    if use_wandb:\n",
    "        config = dict(\n",
    "            model = \"TimeAutoDiff\",\n",
    "            patient_length = patient_length,\n",
    "            imputation_strategy = imputation_strategy,\n",
    "            number_of_features = number_of_features,\n",
    "            epochs_VAE = VAE_training,\n",
    "            epochs_diffusion = diff_training,\n",
    "            pred_task = task_name,\n",
    "            data_name = data_name,\n",
    "        )\n",
    "\n",
    "        use_cuda = torch.cuda.is_available()\n",
    "        wandb.init(\n",
    "            project = 'TimeAutoDiff',\n",
    "            config = config,\n",
    "            name = output_dir.split('/')[-1],\n",
    "        )\n",
    "\n",
    "    ################################################################################################################\n",
    "    # Auto-encoder Training #\n",
    "    ################################################################################################################\n",
    "if train_auto:\n",
    "    torch.cuda.empty_cache()\n",
    "    if efficient:\n",
    "        ds = timeautodiff.train_autoencoder(response, channels, hidden_size, num_layers, lr, weight_decay, n_epochs,\n",
    "                                                      batch_size, min_beta, max_beta, emb_dim, time_dim, lat_dim, device,output_dir, checkpoints=True,\n",
    "                                                    mmd_weight = auto_mmd_weight, consistency_weight = auto_consistency_weight, use_wandb=use_wandb)\n",
    "    # Save Autoencoder\n",
    "    ae = ds[0]\n",
    "    ae.save_model(os.path.join(output_dir, 'autoencoder'))\n",
    "    # Save latent features\n",
    "    latent_features = ds[1]\n",
    "    processing.save_tensor(latent_features,output_dir, 'latent_features.pt')\n",
    "    print(\"Latent features saved successfully.\")\n",
    "else:\n",
    "    latent_features = torch.load(os.path.join(output_dir, 'latent_features.pt'))\n",
    "    ae = timeautodiff.DeapStack.load_model(os.path.join(output_dir, 'autoencoder.pt'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3) Training Diffusion Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "################################################################################################################\n",
    "# Diffusion Training #\n",
    "################################################################################################################\n",
    "if train_diff:\n",
    "    num_classes = len(latent_features)\n",
    "\n",
    "    new_params = {\n",
    "        \"diff_num_classes\" : num_classes,\n",
    "    }   \n",
    "    # Call the method\n",
    "    tdf_helper.append_new_params_to_metadata(output_dir, new_params)\n",
    "\n",
    "    diff = timeautodiff.train_diffusion(latent_features, cond, time_info, hidden_dim, num_layers, diffusion_steps, n_epochs,output_dir,\n",
    "                                        checkpoints = True, num_classes = num_classes,\n",
    "                                        mmd_weight = diff_mmd_weight, consistency_weight = diff_consistency_weight, use_wandb=use_wandb)\n",
    "with open('output_metadata.txt', 'a') as f:\n",
    "    f.write(f\"Metadata: {metadata}, Full Metadata: {full_metadata}, Output Directory: {output_dir}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Generating Synthetic Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1) Model Loading (In case not loaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "################################################################################################################\n",
    "# Model Evaluation\n",
    "################################################################################################################\n",
    "output_dir = f'outputs/{task_name}/{data_name}/TimeAutoDiff/'\n",
    "latest_diffusion_timestamp = sorted(os.listdir(output_dir))[-1]\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"############ Evaluating timestamp {latest_diffusion_timestamp}: ############\")\n",
    "\n",
    "model = tdf_helper.load_models_only(latest_diffusion_timestamp, task_name, data_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2) Sampling from Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "response_train, outcome_train, static_train, time_info_train = processing.process_data_for_synthesizer(X_train, y_train, c_train, top10_important_features)\n",
    "cond_train = torch.concatenate((static_train, outcome_train), axis=2)\n",
    "response_train = response_train.float()\n",
    "time_info_train = time_info_train.float()\n",
    "cond_train = cond_train.float()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "synth_data_list = []\n",
    "synth_data_y_list = []\n",
    "\n",
    "\n",
    "\n",
    "n_generations = 2\n",
    "for i in tqdm.notebook.tqdm(range(n_generations), desc=\"Generating Synthetic Data\", leave=True):\n",
    "\n",
    "\n",
    "\n",
    "    _synth_data = tdf_helper.generate_synthetic_data_in_batches(model, cond_train, time_info_train, \n",
    "                                                                       batch_size = 10000)\n",
    "    _synth_data_y = cond_train[:, 0, -1]\n",
    "    synth_data_list.append(_synth_data.cpu().numpy())\n",
    "    synth_data_y_list.append(_synth_data_y.cpu().numpy().reshape(-1,))\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
